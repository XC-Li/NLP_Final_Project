{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words model\n",
    "Final Project for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idA = {1:'American (Traditional)', 2:'Italian',3:'Mexican',4:'Chinese',5:'American (New)',6:'Japanese', 0:'Other'}\n",
    "idB = {1:'Nightlife', 2:'Fast Food', 3:'Breakfast & Brunch', 4:'Coffee & Tea', 5:'Cafes', 0:'Other'}\n",
    "df = pd.read_pickle(\"typeAB_not_0.pickle\")\n",
    "df_full = pd.read_pickle(\"filtered.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921172\n"
     ]
    }
   ],
   "source": [
    "mini_df = df[:10000]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = mini_df['review']\n",
    "y = mini_df['stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def sentence_tokenizer(s):\n",
    "    \"\"\"sentence tokenizer --modified from EDA version\n",
    "    :parameter \n",
    "        s: String \n",
    "    :return\n",
    "        tokenized_s: String\"\"\"\n",
    "    s = s.lower()\n",
    "    tokenized_s = nltk.word_tokenize(s)\n",
    "    english_stopwords = set(stopwords.words('english'))\n",
    "    tokenized_s = [w for w in tokenized_s if w not in english_stopwords if w.isalpha()]\n",
    "    tokenized_s = \" \".join(tokenized_s)\n",
    "    return tokenized_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:34<00:00, 286.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = []\n",
    "for i in tqdm(range(len(review))):\n",
    "    X.append(sentence_tokenizer(review[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = pd.DataFrame({'review':X,'star':y})\n",
    "processed_df.to_csv('processes_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(analyzer='word', max_features=5000)  #can use n_gram, see document\n",
    "X_train_features = count_vectorizer.fit_transform(X_train)\n",
    "X_train_features = X_train_features.toarray()\n",
    "X_test_features = count_vectorizer.transform(X_test)\n",
    "X_test_features = X_test_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state=42) \n",
    "forest = forest.fit( X_train_features, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and evalutaion\n",
    "\n",
    "Need to choose a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.3669593372208219\n",
      "Accuracy 0.548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('F1 score',f1_score(y_test, y_pred, average='macro'))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
